import requests

page3= "http://www.aflcio.org/Legislation-and-Politics/Legislative-Alerts"
page = requests.get(page3) # downloaded page
#print(page)
#print(page.content)

from bs4 import BeautifulSoup
soup = BeautifulSoup(page.content, 'html.parser')
data = soup.find_all(class_='ec_statements')

data_dict = {}

for entry in data:
    data_list = []
    name = entry.find('a').get_text()
    date = entry.find(id="legalert_date").get_text()
    url = entry.find('a').get('href')
    data_list.append(name)
    data_list.append(date)
    data_list.append("www.aflcio.org"+url)
    data_dict[entry.a.get_text()]= data_list
for i in data_dict:
    print("************************************************")
    for j in data_dict[i]:
        print( j)

"""        
import os, csv
os.chdir("/Python/WebScraper/")

with open("stanford.csv", "w") as toWrite:
"""    
import json

with open("/Python/WebScraper/stanford.json", "w") as writeJSON:
    json.dump(data_dict, writeJSON)
